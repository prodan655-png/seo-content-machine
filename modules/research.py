import streamlit as st
from utils.state_manager import save_state

def render_research(selected_project, strategist, API_KEY, file_manager):
    """
    Renders the Research page with Topic Ideas and SERP Analysis tabs.
    
    Args:
        selected_project: Name of the currently selected project
        strategist: Strategist agent instance
        API_KEY: Gemini API key
        file_manager: FileManager instance
    """
    st.title("üîç –î–æ—Å–ª—ñ–¥–∂–µ–Ω–Ω—è —Ç–∞ –ê–Ω–∞–ª—ñ–∑")
    
    # Tabs for different research features
    research_tab1, research_tab2, research_tab3 = st.tabs(["üí° –Ü–¥–µ—ó –¢–µ–º", "üîé SERP –ê–Ω–∞–ª—ñ–∑", "üîë –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ö–ª—é—á—ñ–≤"])
    
    with research_tab1:
        _render_topic_ideas(selected_project, strategist, API_KEY, file_manager)
    
    with research_tab2:
        _render_serp_analysis(selected_project, strategist, API_KEY)

    with research_tab3:
        _render_keyword_generator(selected_project, strategist, API_KEY, file_manager)
    
    # Display research results if available
    if st.session_state.get('research_data'):
        _display_research_results(selected_project, strategist, file_manager)


def _render_topic_ideas(selected_project, strategist, API_KEY, file_manager):
    """Renders the Topic Ideas generator tab."""
    st.subheader("üí° –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –Ü–¥–µ–π –¢–µ–º")
    st.markdown("–í–≤–µ–¥—ñ—Ç—å –≤–∞—à—É –Ω—ñ—à—É, —ñ —è –∑–≥–µ–Ω–µ—Ä—É—é 10 —ñ–¥–µ–π –¥–ª—è —Å—Ç–∞—Ç–µ–π.")
    
    col1, col2 = st.columns([3, 1], vertical_alignment="bottom")
    with col1:
        niche_input = st.text_input("–ù—ñ—à–∞/–Ü–Ω–¥—É—Å—Ç—Ä—ñ—è", placeholder="–Ω–∞–ø—Ä. –í–∏–ø—ñ—á–∫–∞, –§—ñ—Ç–Ω–µ—Å, –ï–ª–µ–∫—Ç—Ä–æ–Ω—ñ–∫–∞")
    
    # Context Options
    with st.expander("üß† –î–æ–¥–∞—Ç–∫–æ–≤–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–¥–ª—è –∫—Ä–∞—â–∏—Ö —ñ–¥–µ–π)"):
        # Check for sitemap
        pages_content = file_manager.read_file(selected_project, "pages.csv")
        has_sitemap = pages_content is not None and len(pages_content) > 10
        
        # Check for competitor data
        has_competitors = False # Placeholder, as we don't have a global competitor DB yet
        
        c1, c2 = st.columns(2)
        with c1:
            use_competitors = st.checkbox("–í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤", value=True, disabled=not has_competitors)
            if not has_competitors:
                st.caption("‚ùå –î–∞–Ω—ñ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤ –≤—ñ–¥—Å—É—Ç–Ω—ñ")
            else:
                st.caption("‚úÖ –î–∞–Ω—ñ –¥–æ—Å—Ç—É–ø–Ω—ñ")
                
        with c2:
            use_sitemap = st.checkbox("–í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –∫–∞—Ä—Ç—É —Å–∞–π—Ç—É", value=has_sitemap, disabled=not has_sitemap)
            if has_sitemap:
                page_count = len(pages_content.split('\n')) - 1
                st.caption(f"‚úÖ Sitemap –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ ({page_count} —Å—Ç–æ—Ä—ñ–Ω–æ–∫)")
            else:
                st.caption("‚ùå Sitemap –≤—ñ–¥—Å—É—Ç–Ω—ñ–π (–∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –≤ –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö)")
    
    with col2:
        generate_topics_btn = st.button("üöÄ –ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏", use_container_width=True)
    
    if generate_topics_btn and niche_input:
        if not API_KEY:
            st.error("‚ö†Ô∏è API Key –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!")
        else:
            with st.spinner(f"–ì–µ–Ω–µ—Ä—É—é —ñ–¥–µ—ó –¥–ª—è: {niche_input}..."):
                try:
                    # Gather context
                    context_data = ""
                    if use_competitors:
                        # Try to load competitor data from previous research
                        pass # For now, we don't have a global competitor DB, but we could load from files
                    
                    if use_sitemap:
                        # Load sitemap pages
                        pages_csv = file_manager.read_file(selected_project, "pages.csv")
                        if pages_csv:
                            context_data += f"Existing pages on site (DO NOT DUPLICATE):\n{pages_csv[:2000]}\n"
                            
                    topics = strategist.generate_topic_ideas(niche_input, num_topics=10, context_data=context_data)
                    st.session_state.topic_ideas = topics
                    st.success(f"–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ {len(topics)} —ñ–¥–µ–π!")
                except Exception as e:
                    st.error(f"–ü–æ–º–∏–ª–∫–∞: {e}")
    
    if st.session_state.get('topic_ideas'):
        st.divider()
        st.markdown("### üìã –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω—ñ –¢–µ–º–∏")
        for i, topic in enumerate(st.session_state.topic_ideas, 1):
            with st.expander(f"**{i}. {topic.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏')}**"):
                st.markdown(topic.get('description', '–û–ø–∏—Å –≤—ñ–¥—Å—É—Ç–Ω—ñ–π'))
                if st.button(f"–í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ —Ü—é —Ç–µ–º—É", key=f"use_topic_{i}"):
                    st.session_state.selected_topic_for_analysis = topic.get('title')
                    st.success(f"–¢–µ–º–∞ –æ–±—Ä–∞–Ω–∞! –ü–µ—Ä–µ–π–¥—ñ—Ç—å –¥–æ –≤–∫–ª–∞–¥–∫–∏ 'SERP –ê–Ω–∞–ª—ñ–∑'")


def _render_keyword_generator(selected_project, strategist, API_KEY, file_manager):
    """Renders the Keyword Generator tab."""
    st.subheader("üîë –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ö–ª—é—á–æ–≤–∏—Ö –°–ª—ñ–≤")
    st.markdown("–ó–≥–µ–Ω–µ—Ä—É–π—Ç–µ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–µ —è–¥—Ä–æ –¥–ª—è –≤–∞—à–æ—ó —Ç–µ–º–∏.")
    
    topic_input = st.text_input("–¢–µ–º–∞ –¥–ª—è –ø—ñ–¥–±–æ—Ä—É –∫–ª—é—á—ñ–≤", value=st.session_state.get('selected_topic_for_analysis', ''))
    
    if st.button("üé≤ –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ö–ª—é—á—ñ"):
        if not topic_input:
            st.error("–í–≤–µ–¥—ñ—Ç—å —Ç–µ–º—É!")
        else:
            with st.spinner("–ü—ñ–¥–±–∏—Ä–∞—é –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞..."):
                try:
                    keywords = strategist.generate_keywords(topic_input)
                    st.session_state.generated_keywords = keywords
                except Exception as e:
                    st.error(f"–ü–æ–º–∏–ª–∫–∞: {e}")

    if st.session_state.get('generated_keywords'):
        import pandas as pd
        df = pd.DataFrame(st.session_state.generated_keywords)
        st.dataframe(df, use_container_width=True)
        
        # Save option
        if st.button("üíæ –ó–±–µ—Ä–µ–≥—Ç–∏ –≤ Semantic Core"):
            # Convert to CSV string
            csv_data = df.to_csv(index=False)
            file_manager.save_file(selected_project, "semantic_core.csv", csv_data)
            st.success("‚úÖ –ö–ª—é—á—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ –ø—Ä–æ–µ–∫—Ç!")


def _render_serp_analysis(selected_project, strategist, API_KEY):
    """Renders the SERP Analysis tab."""
    st.subheader("üîé SERP –ê–Ω–∞–ª—ñ–∑")
    
    # Pre-fill if topic was selected from Topic Ideas
    default_topic = st.session_state.get('selected_topic_for_analysis', '')

    with st.form(key='search_form'):
        col1, col2 = st.columns([3, 1], vertical_alignment="bottom")
        with col1:
            topic = st.text_input("–í–≤–µ–¥—ñ—Ç—å —Ç–µ–º—É", placeholder="–Ω–∞–ø—Ä. –ü—Ä–µ—Å–æ–≤–∞–Ω—ñ –¥—Ä—ñ–∂–¥–∂—ñ", value=default_topic)
        with col2:
            analyze_btn = st.form_submit_button("üöÄ –ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏", use_container_width=True)
    
    if analyze_btn:
        if not API_KEY:
            st.error("‚ö†Ô∏è API Key –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ! –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ .env —Ñ–∞–π–ª.")
        else:
            with st.spinner(f"–ê–Ω–∞–ª—ñ–∑—É—é –≤–∏–¥–∞—á—É –¥–ª—è: {topic}..."):
                try:
                    serp_data = strategist.analyze_serp(topic)
                    st.session_state.research_data = serp_data
                    
                    # Save state
                    save_state(selected_project, {
                        'research_data': serp_data,
                        'selected_project': selected_project
                    })
                    
                    st.success(f"–ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {topic}")
                except Exception as e:
                    st.error(f"–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É: {e}")


def _display_research_results(selected_project, strategist, file_manager):
    """Displays SERP analysis results."""
    data = st.session_state.research_data
    
    # Intent & Features
    c1, c2 = st.columns(2)
    with c1:
        st.info(f"**–Ü–Ω—Ç–µ–Ω—Ç (–ù–∞–º—ñ—Ä):** {data.get('intent', '–ù–µ –≤–∏–∑–Ω–∞—á–µ–Ω–æ')}")
    with c2:
        feats = ", ".join(data.get('serp_features', []))
        st.warning(f"**SERP –§—ñ—á—ñ:** {feats if feats else '–ù–µ–º–∞—î –æ—Å–æ–±–ª–∏–≤–∏—Ö —Ñ—ñ—á'}")
    
    st.subheader("üîç –Ü–Ω—Å–∞–π—Ç–∏ –∑ –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤")
    
    # Competitors Accordion
    if data.get('competitor_outlines'):
        for comp in data['competitor_outlines']:
            with st.expander(f"üìÑ {comp.get('h1', 'No Title')} ({comp['url']})"):
                st.write("**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**")
                for h in comp.get('structure', []):
                    st.text(h)
    else:
        st.info("–î–µ—Ç–∞–ª—å–Ω—ñ –∞—É—Ç–ª–∞–π–Ω–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤ —â–µ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –∫–Ω–æ–ø–∫—É –Ω–∏–∂—á–µ.")
        
        if st.button("üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤"):
            with st.spinner("–°–∫–∞–Ω—É—é —Å–∞–π—Ç–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ñ–≤..."):
                try:
                    urls = [r['url'] for r in data['competitors']]
                    outlines = strategist.analyze_competitors(urls)
                    st.session_state.research_data['competitor_outlines'] = outlines
                    
                    # Save state
                    save_state(selected_project, {'research_data': st.session_state.research_data})
                    
                    st.rerun()
                except Exception as e:
                    st.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏: {e}")
